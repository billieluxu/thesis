\chapter{Related Work}
\label{ch:related}

Byzantine consensus has a rich history that spans cryptography, distributed computing, and economics,
but the socio-economic context for its products to be deployed in industry has not existed until recently,
at least not outside of traditionally critical real-time systems like air-craft control \ref{draper_lab}.
On the one hand, the invention of Bitcoin and the coining of the term "blockchain" popularized the notion
of a distributed ledger not controlled by a single entity, using cryptography and aligned economic incentives to 
preserve safety in the face of Byzantine faults.
On the other, the continued commoditization of servers, in the form of "The Cloud", and the invention of Raft, 
have popularized distributed computing in mainstream developer culture, 
and brought renewed attention to distributed consensus algorithms as co-ordination hubs in large-scale deployments. 

At the intersection are a collection of solutions, typically geared for banking and financial applications,
but also for governance, logistics, and other general forms of co-ordination, 
that draw on classic academic BFT modified and modernized in various ways.
This chapter reviews the history and diversity of these ideas, with the goal of providing a rich context within which to 
understand the blockchain phenomenon.

\section{Beginnings}

Distribtued algorithms first emerged in the late 19th century in the telecommunications and railroad industries,
in attempts to effectively handle multiple concurrent message streams in a transmission, 
or multiple trains on the same set of tracks.

Academic work on the subject appears to have been launched officially by the seminal work
of Edsger Dijkstra on the mutual exclusion problem \ref{mutex}, and of Tony Hoare on models for describing communicating processes.\ref{csp}, 

A host of concurrency problems with catchy names were popularized around this time,
including the cigarette smokers problem \ref{cigarette_smokers}, where smokers sit around a table, 
each with a different ingredient, and must successfully roll a full cigarettte,
and the dinning philosophers problem \ref{dining_philosophers},
where philosophers sitting around a table must take turns eating and thinking,
but each can only eat while its neighnours are thinking.

These problems served to put the focus on synchronization primitives
such as semaphores, mutexes, and communication channels,
and would lay the ground for a number of advancements over the coming decades.

\subsection{Faulty Things}

Fault tolerant distributed computing effectively emerged in the late seventies 
out of the effort to utilize microprocessors for aircraft control, resulting in a number of early systems \ref{sift,ftmp}.
Today, it is standard for NASA to conduct BFT research \ref{miner2004unified}, 
and for commercial aircraft to use BFT systems, such as the SAFEbus \ref{hoyme1993safebus}.

Many systems, however, do not require tolerance to Byzantine faults as they are run in controlled environments,
where there is presumably no malicious behaviour and the code is written correctly.
In these circumstances, which are common in data-centers managed by large companies like Google or Amazon,
fault tolerant computing is used to defend against various faults,
whether it be a break in a network link, power failure in a server rack, or a dead harddrive.

\subsection{Clocks}

The problem of distribtued consensus, however, did not formally emerge until Leslie Lemport introduced it in his 
"Time, clocks, and the ordering of events in a distribetud system" \ref{clocks}.
In that work, Lamport demonstrated how a partial ordering of events emerges from a definition of causality based on communication \ref{clocks}.
That is, events occuring in concurrent processes, between communication events, 
effectively happen at the same time, as they cannot influence one another.
Thus, a system of logical clocks can be defined based on the individual sequential processes 
and the fact that messages are sent before they are received.
Events can then be totally ordered by assigning any arbitrary but consistent total ordering above the partial ordering,
for instance by assigning each process in the system an index and ordering events which happen at the same logical time by the
index of the process in which they happen.
The algorithm is quite simple, requiring each process to hear from each other process in order to determine the order of events.

Lamport's work established time as a principle obstacle to designing fault tolerant distributed systems,
as synchronizing clocks across geographical locations requires the communication of messages 
which is ultimately limited by the speed of light.
This formulation of the problem has close ties to the relativism of modern physics,
wherein frames of reference are relative to an observer and the speed of light imposes a constraint on information propogation.

\subsection{FLP}
As discussed in Chapter \ref{ch:motivation}, 
one of the primary factors in designing consensus algorithms are assumptions made about 
network and/or processor synchrony. 
A synchronous network is one in which messages are delivered within some fixed, 
known amount of time. 
Similarly, synchronous processors are one whose clocks stay within some fixed, 
known number of ticks of eachother.
In the early days of consensus research, the distinction was not well characterized, 
though the close relationship between asynchrony and crash failures is apparent even in \ref{clocks}.
Lamports original consensus algorithm is able to operate in asynchronous environments, 
so long as all messages are eventually delivered from each process.
However, the algorithm is obviously not fault tolerant as the failure of just a single process can halt the algorithm forever.

The intuition behind a single failure thwarting a consensus protocol was given formal ground by Fischer, Lynch, and Patterson,
who proved the impossibility of deterministic distribtued consensus in asynchronous environments if even a single process can fail \ref{flp}.
The result does not apply to synchronous contexts, 
as assumptions about network synchrony allow processors to detect failures using timeouts, 
such that if a process does not respond within some given amount of time it is assumed to have crashed.
Furthermore, the result applies to deterministic consensus protocols only, 
as its proof relies on the moment when the network goes deterministically from a bivalent state, 
where not all processes hold the same value, to a univalent one, where they do.
Since the point of transition is a deterministic point in time, 
consensus fails if a single processes crashes at that opportune moment.

\subsection{Common Coin}

The FLP result became something of a warning bell to distributed systems scientists, 
establishing a clear impossibility result at the heart of the emerging field.
Later, the approach would be generalized to derrive many more impossibility results \ref{impossibility},
and significant academic effort would be expended on relaxing either the synchrony or determinism assumptions to derrive algorithms which circumvent the result.

In particular, in a short note, 
Ben Or demonstrated how an algorithm which includes a simple amount of non-determinism can circumvent the FLP result \ref{free-choice}.
The algorithm is tolerant to faults of up to half of the processes in asynchronous environments.
Essentially, in trying to reach consensus on the value of a single bit, 
if a process does not receive votes from a majority for the same value, it randomly changes the value it votes for the next round.
With everyone changing values, eventually more than half of them will vote the same value.
This approach came to be known as a "common coin", 
due to the resemblance of the procedure to communally flipping a coin to obtain a shared value.

The problem with Ben Or's common coin is that, in the asynchronous case,
the algorithm requires a number of rounds exponential in the number of validators.
This was quickly rectified in a follow up by Rabin, who showed how a common coin
could be constructed using secret sharing, as pioneered by Shamir \ref{shamir1979share},
to achieve consensus in a fixed number of rounds \ref{rabin1983randomized}.
The approach is useful for BFT as well, and is discussed more fully in that context in a later section.

\subsection{Transaction Processing}

Parallel to the development of fault tolerant consensus algorithms was the emergence of the first commercial database systems.
While they did not at first use the consensus protocols being developed, 
they built atop the growing body of work in distributed computing and concurrency.
In particular is the seminal work of Jim Gray, who introduced the term \emph{transaction} 
as an atomic unit of work in a database system \ref{gray1981transaction}. 
That is, a transaction is either applied in full or not at all.

Jim also introduced other classic features of modern databases,
such as the principles of ACIDity (Atomicity, Consistency, Isolation, and Durability),
and the use of write-ahead-logs, for logging transactions to disk before they are executed
in order to recover from faults occuring during transaction execution.



atomic commit, 2pc, 3pc, database replication
transaction serializability (Eswar 76)

\subsection{Broadcast Protocols}
reliable broadcast, atomic broadcast

\section{Byzantine}
	\subsection{Byzantine Generals}
	\subsection{Randomized Consensus}
	\subsection{DLS}
	\subsection{PBFT}
		- pbft: pre-prepare, prepare, commit; view changes; lack of gaurantees.
	\subsection{PBFT Derivatives} 
		- pbft improvements

\section{Non-Byzantine}
	\subsection{view stamped replication}
	\subsection{paxos}
	\subsection{zab}
	\subsection{spanner}
	\subsection{riak}
	\subsection{raft} leaderelection, log replication, safety. subtleties. no bft

\section{P2P}
	napster, bittorent, kademlia, chord, tahoe-lafs, ipfs
	boinc, seti, folding@home

\section{Blockchain}
	\subsection{bitcoin} Incentive incompatibility issues, attempts to scale, sidechains, lightning, seg-wit, Bitcoin-NG,
	treeee signatures, ghost, etc.
	\subsection{ethereum}
	\subsection{proof of stake}
	\subsection{juno, sieve}
	\subsection{honeybadger}


\section{Conclusion}

